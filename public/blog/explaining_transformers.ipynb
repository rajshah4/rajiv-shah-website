{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Explaining predictions from ü§ó transformer models\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://rajivshah.com/blog/images/transformers/banner.png\"\n",
        "alt=\"Banner\" />\n",
        "<figcaption aria-hidden=\"true\">Banner</figcaption>\n",
        "</figure>\n",
        "\n",
        "### Introduction\n",
        "\n",
        "This post covers 3 easy-to-use üì¶ packages to get started. You can also\n",
        "check out the Colab üìì companion notebook at https://bit.ly/raj_explain\n",
        "and the Youtube üé• [video](https://youtu.be/j6WbCS0GLuY) for a deeper\n",
        "treatment.\n",
        "\n",
        "Explanations are useful for explaining predictions. In the case of text,\n",
        "they highlight how the text influenced the prediction. They are helpful\n",
        "for ü©∫ diagnosing model issues, üëÄ showing stakeholders understand how a\n",
        "model is working, and üßë‚Äç‚öñÔ∏è meeting regulatory requirements. Here is an\n",
        "explanation üëá using shap. For more on explanations, check out the\n",
        "[explanations in machine learning video](https://youtu.be/SVfrxFdJNB4).\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://rajivshah.com/blog/images/transformers/shap.png\"\n",
        "alt=\"Screen Shot 2022-08-12 at 9.25.07 AM\" />\n",
        "<figcaption aria-hidden=\"true\">Screen Shot 2022-08-12 at 9.25.07\n",
        "AM</figcaption>\n",
        "</figure>\n",
        "\n",
        "Let‚Äôs review 3 packages you can use to get explanations. All of these\n",
        "work with transformers, provide visualizations, and only require a few\n",
        "lines of code.\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://rajivshah.com/blog/images/transformers/code.png\"\n",
        "alt=\"Red and Purple Real Estate Soft Gradients Twitter Ad (1)\" />\n",
        "<figcaption aria-hidden=\"true\">Red and Purple Real Estate Soft Gradients\n",
        "Twitter Ad (1)</figcaption>\n",
        "</figure>\n",
        "\n",
        "### Shap\n",
        "\n",
        "1.  [SHAP](https://github.com/slundberg/shap) is a well-known,\n",
        "    well-regarded, and robust package for explanations. In working with\n",
        "    text, SHAP typically defers to using a Partition Shap explainer.\n",
        "    This method makes the shap computation tractable by using\n",
        "    hierarchical clustering and Owens values. The image here shows the\n",
        "    clustering for a simple phrase. If you want to learn more about\n",
        "    Shapley values, I have a [video on shapley\n",
        "    values](https://youtu.be/DYA5SA0edb0) and a deep dive on [Partition\n",
        "    Shap explainer is\n",
        "    here](https://towardsdatascience.com/shaps-partition-explainer-for-language-models-ec2e7a6c1b77).\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://rajivshah.com/blog/images/transformers/cluster.png\"\n",
        "alt=\"Screen Shot 2022-08-12 at 9.35.34 AM\" />\n",
        "<figcaption aria-hidden=\"true\">Screen Shot 2022-08-12 at 9.35.34\n",
        "AM</figcaption>\n",
        "</figure>\n",
        "\n",
        "### Transformers Interpret\n",
        "\n",
        "1.  [Transformers\n",
        "    Interpret](https://github.com/cdpierse/transformers-interpret) uses\n",
        "    Integrated Gradients from [Captum](https://captum.ai/) to calculate\n",
        "    the explanations. This approach is üêá quicker than shap! Check out\n",
        "    [this\n",
        "    space](https://huggingface.co/spaces/rajistics/interpet_transformers)\n",
        "    to see a demo.\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://rajivshah.com/blog/images/transformers/ti.png\"\n",
        "alt=\"Screen Shot 2022-08-12 at 9.27.04 AM\" />\n",
        "<figcaption aria-hidden=\"true\">Screen Shot 2022-08-12 at 9.27.04\n",
        "AM</figcaption>\n",
        "</figure>\n",
        "\n",
        "### Ferret\n",
        "\n",
        "1.  [Ferret](https://github.com/g8a9/ferret) is built for benchmarking\n",
        "    interpretability techniques and includes multiple explanation\n",
        "    methodologies (including Partition Shap and Integrated Gradients). A\n",
        "    spaces [demo for ferret is\n",
        "    here](https://huggingface.co/spaces/g8a9/ferret) along with [a\n",
        "    paper](https://arxiv.org/abs/2208.01575) that explains the various\n",
        "    metrics incorporated in ferret.\n",
        "\n",
        "    You can see below how explanations can differ when using different\n",
        "    explanation methods. A great reminder that explanations for text are\n",
        "    complicated and need to be appropriately caveated.\n",
        "\n",
        "    <figure>\n",
        "    <img src=\"https://rajivshah.com/blog/images/transformers/ferret.png\"\n",
        "    alt=\"Screen Shot 2022-08-11 at 1.19.05 PM\" />\n",
        "    <figcaption aria-hidden=\"true\">Screen Shot 2022-08-11 at 1.19.05\n",
        "    PM</figcaption>\n",
        "    </figure>\n",
        "\n",
        "    Ready to dive in? üü¢\n",
        "\n",
        "    For a longer walkthrough of all the üì¶ packages with code snippets,\n",
        "    web-based demos, and links to documentation/papers, check out:\n",
        "\n",
        "    üëâ Colab notebook: https://bit.ly/raj_explain\n",
        "\n",
        "    üé• https://youtu.be/j6WbCS0GLuY"
      ],
      "id": "cc7fd3ac-8005-455f-ab2b-b339f1ec6637"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  }
}