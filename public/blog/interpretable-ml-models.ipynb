{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Interpretable Machine Learning Models Simply Explained\n",
        "\n",
        "## Video\n",
        "\n",
        "<https://youtu.be/lx4SJOVtxI8>\n",
        "\n",
        "Watch the [full video](https://youtu.be/lx4SJOVtxI8)\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "## Annotated Presentation\n",
        "\n",
        "Below is an annotated version of the presentation, with timestamped\n",
        "links to the relevant parts of the video for each slide.\n",
        "\n",
        "Here is the annotated presentation for “Rules: A Simple & Effective\n",
        "Machine Learning Approach” by Rajiv Shah.\n",
        "\n",
        "### 1. Title Slide\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_1.png\"\n",
        "alt=\"Slide 1\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 1</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:00:00](https://youtu.be/lx4SJOVtxI8&t=0s))\n",
        "\n",
        "The presentation begins by introducing the core topic: **Interpretable\n",
        "Models** and the use of rules in machine learning. Rajiv Shah sets the\n",
        "stage by contrasting this talk with previous discussions on\n",
        "explainability (using tools to explain complex models). Instead, this\n",
        "session focuses on choosing models that are inherently easy to\n",
        "understand.\n",
        "\n",
        "Shah expresses his interest in how machine learning helps us understand\n",
        "the world. He notes that while tools like SHAP or LIME help unpack\n",
        "complex models, there is immense value in approaching the problem\n",
        "differently: by selecting model architectures that are transparent by\n",
        "design.\n",
        "\n",
        "The speaker invites the audience to view this not just as a technical\n",
        "lecture but as a discussion on the trade-offs between model complexity\n",
        "and interpretability, setting a collaborative tone for the presentation.\n",
        "\n",
        "### 2. Table of Contents\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_2.png\"\n",
        "alt=\"Slide 2\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 2</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:02:30](https://youtu.be/lx4SJOVtxI8&t=150s))\n",
        "\n",
        "This slide outlines the roadmap for the presentation. Shah explains that\n",
        "he will begin with the “Big Picture” concepts—specifically the\n",
        "**“Why?”** and the **“Baseline”**—before diving into four specific\n",
        "technical approaches to rule-based modeling.\n",
        "\n",
        "The four specific methods to be covered are **Rulefit**, **GA2M**\n",
        "(Generalized Additive Models with interactions), **Rule Lists**, and\n",
        "**Scorecards**. This structure moves from theoretical justification to\n",
        "practical application, comparing different algorithms that prioritize\n",
        "transparency.\n",
        "\n",
        "Shah also mentions that a GitHub repository is available with code\n",
        "examples for everything shown, allowing the audience to reproduce the\n",
        "results for the tabular datasets discussed.\n",
        "\n",
        "### 3. Section 1: Why?\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_3.png\"\n",
        "alt=\"Slide 3\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 3</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:03:09](https://youtu.be/lx4SJOVtxI8&t=189s))\n",
        "\n",
        "This section header introduces the fundamental question: **Why do we\n",
        "want rules?** The speaker moves past the obvious statement that “AI is\n",
        "important” to investigate the influences that drive data scientists\n",
        "toward complex, opaque models.\n",
        "\n",
        "Shah prepares to discuss the cultural and competitive pressures in data\n",
        "science that prioritize raw accuracy over usability. This section serves\n",
        "as a critique of the “accuracy at all costs” mindset often found in the\n",
        "industry.\n",
        "\n",
        "### 4. Mark Cuban Quote\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_4.png\"\n",
        "alt=\"Slide 4\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 4</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:03:17](https://youtu.be/lx4SJOVtxI8&t=197s))\n",
        "\n",
        "The slide features a quote from Mark Cuban: *“Artificial Intelligence,\n",
        "deep learning, machine learning — whatever you’re doing if you don’t\n",
        "understand it — learn it. Because otherwise you’re going to be a\n",
        "dinosaur within 3 years.”*\n",
        "\n",
        "Shah briefly references this as the “obligatory” acknowledgment of AI’s\n",
        "massive importance in the current landscape. It reinforces that while\n",
        "the field is moving fast, the *understanding* of these systems is\n",
        "paramount, which ties into the presentation’s focus on interpretability.\n",
        "\n",
        "### 5. Influences: Kaggle & Academia\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_5.png\"\n",
        "alt=\"Slide 5\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 5</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:03:40](https://youtu.be/lx4SJOVtxI8&t=220s))\n",
        "\n",
        "Shah identifies **Kaggle competitions** and academic research as two\n",
        "primary influences on data scientists. He notes that these platforms\n",
        "heavily incentivize accuracy above all else. For example, in the Zillow\n",
        "Prize, the difference between the top scores is minuscule, yet teams\n",
        "fight for that fraction of a percentage.\n",
        "\n",
        "He argues that this environment trains data scientists to focus solely\n",
        "on improving metrics (like RMSE or AUC), often ignoring other critical\n",
        "trade-offs like model complexity, deployment difficulty, or\n",
        "explainability.\n",
        "\n",
        "As he states, *“One of the byproducts of Kaggle is a very heavy focus on\n",
        "making sure you improve your models around accuracy… and that’s how you\n",
        "can get a conference paper.”* This sets up the problem of complexity\n",
        "creep.\n",
        "\n",
        "### 6. The Netflix Prize Winners\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_6.png\"\n",
        "alt=\"Slide 6\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 6</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:05:39](https://youtu.be/lx4SJOVtxI8&t=339s))\n",
        "\n",
        "This slide shows the winners of the famous **Netflix Prize**, a\n",
        "competition held about 15 years ago where a team won \\$1 million for\n",
        "improving Netflix’s recommendation algorithm by 10%.\n",
        "\n",
        "Shah uses this story to illustrate the peak of the “accuracy” mindset.\n",
        "The competition drew massive interest and drove innovation, but it also\n",
        "encouraged teams to prioritize the leaderboard score over the\n",
        "practicality of the solution.\n",
        "\n",
        "### 7. Netflix Prize Progress Graph\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_7.png\"\n",
        "alt=\"Slide 7\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 7</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:06:14](https://youtu.be/lx4SJOVtxI8&t=374s))\n",
        "\n",
        "The graph displays the progress of teams over time during the Netflix\n",
        "competition. Shah points out that after an initial period of rapid\n",
        "improvement using standard algorithms, progress plateaued.\n",
        "\n",
        "To break through these plateaus, teams began using\n",
        "**Ensembling**—combining multiple models together. The winning solution\n",
        "was an ensemble of **107 different models**. Shah emphasizes that while\n",
        "this strategy is powerful for eking out the last bit of performance, it\n",
        "creates immense complexity.\n",
        "\n",
        "### 8. The Engineering Cost of Complexity\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_8.png\"\n",
        "alt=\"Slide 8\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 8</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:07:39](https://youtu.be/lx4SJOVtxI8&t=459s))\n",
        "\n",
        "This slide reveals the ironic conclusion of the Netflix Prize: the\n",
        "winning model was **never implemented**. The engineering costs to deploy\n",
        "an ensemble of 107 models were simply too high compared to the marginal\n",
        "gain in accuracy.\n",
        "\n",
        "Shah uses this as a cautionary tale: *“If your focus is on accuracy… it\n",
        "drives you down towards this complexity… but often you end up with these\n",
        "complex models \\[that\\] are often very difficult to implement.”* This\n",
        "highlights the disconnect between competitive data science and\n",
        "enterprise reality.\n",
        "\n",
        "### 9. Understandable White Box Model (CLEAR-2)\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_9.png\"\n",
        "alt=\"Slide 9\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 9</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:08:04](https://youtu.be/lx4SJOVtxI8&t=484s))\n",
        "\n",
        "Shah transitions to the alternative: **Interpretable Models**. This\n",
        "slide shows a simple linear model (CLEAR-2) with only two features. This\n",
        "is a classic “White Box” model where the relationship between inputs and\n",
        "outputs is transparent.\n",
        "\n",
        "The speaker contrasts this with the “Black Box” nature of complex\n",
        "ensembles. He argues that if you cannot understand what is going on\n",
        "inside a model, you cannot effectively debug it, nor can you easily\n",
        "convince stakeholders to trust it.\n",
        "\n",
        "### 10. Complex White Box Model (CLEAR-8)\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_10.png\"\n",
        "alt=\"Slide 10\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 10</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:11:51](https://youtu.be/lx4SJOVtxI8&t=711s))\n",
        "\n",
        "This slide presents a linear model with eight features (CLEAR-8). While\n",
        "technically still a “White Box” model, Shah implies that as feature\n",
        "counts grow, true understandability diminishes.\n",
        "\n",
        "He touches on this concept later in the “Caveats” section, noting that\n",
        "even linear models can become confusing if there is\n",
        "**multicollinearity** (features moving in the same direction). Just\n",
        "because we can see the coefficients doesn’t mean the model is\n",
        "intuitively “explainable” to a human if the variables interact in\n",
        "complex, non-obvious ways.\n",
        "\n",
        "### 11. Easy to Understand Decision Tree\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_11.png\"\n",
        "alt=\"Slide 11\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 11</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:19:15](https://youtu.be/lx4SJOVtxI8&t=1155s))\n",
        "\n",
        "Here, a simple Decision Tree is presented. Shah connects this to the\n",
        "history of rule-based learning, noting that early research found that\n",
        "keeping decision trees “short and stumpy” made them very easy for humans\n",
        "to explain.\n",
        "\n",
        "This visual represents the ideal of interpretability: a clear path of\n",
        "logic (e.g., “If X is less than 3, go left”) that leads to a prediction.\n",
        "This is the foundation for the **Rulefit** method discussed later.\n",
        "\n",
        "### 12. Too Much to Comprehend\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_12.png\"\n",
        "alt=\"Slide 12\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 12</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:07:46](https://youtu.be/lx4SJOVtxI8&t=466s))\n",
        "\n",
        "Contrasting the previous slide, this image shows a chaotic forest of\n",
        "decision trees. This represents modern ensemble methods like Random\n",
        "Forests or Gradient Boosted Machines.\n",
        "\n",
        "Shah uses this visual to reinforce the point that while ensembles offer\n",
        "**“Better Performance,”** the sheer number of decision paths makes them\n",
        "**“too much to Comprehend.”** You lose the ability to trace the “why”\n",
        "behind a specific prediction, turning the system into a Black Box.\n",
        "\n",
        "### 13. Pedro Domingos Tweet\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_13.png\"\n",
        "alt=\"Slide 13\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 13</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:08:22](https://youtu.be/lx4SJOVtxI8&t=502s))\n",
        "\n",
        "Shah acknowledges the counter-argument by showing a tweet from Pedro\n",
        "Domingos, a prominent machine learning researcher, who suggests that\n",
        "demanding explainability limits the potential of AI.\n",
        "\n",
        "Shah respectfully disagrees with this stance in the context of\n",
        "enterprise data science. He argues that in the real world, *“If you\n",
        "don’t understand what’s going on in your model, it’s hard for you to\n",
        "debug it, it’s hard to convince somebody else to adopt your model.”*\n",
        "Practicality and trust often outweigh raw theoretical power.\n",
        "\n",
        "### 14. Benefits of Interpretable Models\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_14.png\"\n",
        "alt=\"Slide 14\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 14</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:09:16](https://youtu.be/lx4SJOVtxI8&t=556s))\n",
        "\n",
        "This slide summarizes the key benefits of using interpretable models,\n",
        "referencing the work of **Cynthia Rudin**. The main advantages are: 1.\n",
        "**Debugging:** It is easier to spot weird behaviors. 2. **Trust:**\n",
        "Stakeholders and legal/risk teams are more likely to approve the model.\n",
        "3. **Deployment:** These models can often be deployed as simple SQL\n",
        "queries or basic code, avoiding the need for heavy GPU infrastructure.\n",
        "\n",
        "Shah emphasizes the deployment aspect: *“You don’t have to go out and\n",
        "get a GPU… you can actually deploy directly within a database.”*\n",
        "\n",
        "### 15. Caveats of Interpretable Models\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_15.png\"\n",
        "alt=\"Slide 15\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 15</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:11:00](https://youtu.be/lx4SJOVtxI8&t=660s))\n",
        "\n",
        "Shah provides a necessary reality check. He clarifies that selecting an\n",
        "interpretable *algorithm* is only one part of the process. True\n",
        "interpretability depends on the entire data pipeline.\n",
        "\n",
        "Issues like **data labeling**, **feature engineering**, and\n",
        "**multicollinearity** can render even a simple model confusing. For\n",
        "example, if two correlated features have opposite coefficients in a\n",
        "linear model, it becomes very difficult to explain the logic to a\n",
        "business user, even if the math is simple.\n",
        "\n",
        "### 16. Section 2: Baseline\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_16.png\"\n",
        "alt=\"Slide 16\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 16</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:12:15](https://youtu.be/lx4SJOVtxI8&t=735s))\n",
        "\n",
        "This slide introduces the **Baseline** section. Shah advocates for\n",
        "always starting a project with a simple baseline model to establish a\n",
        "performance benchmark.\n",
        "\n",
        "He shares an anecdote about people spending a year on a project only to\n",
        "be nearly matched by a simple model built in two hours. Establishing a\n",
        "baseline helps determine how much effort should be spent chasing\n",
        "incremental accuracy improvements.\n",
        "\n",
        "### 17. The Problem: UCI Adult Dataset\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_17.png\"\n",
        "alt=\"Slide 17\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 17</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:12:54](https://youtu.be/lx4SJOVtxI8&t=774s))\n",
        "\n",
        "Shah introduces the dataset he will use for all examples in the talk:\n",
        "the **UCI Adult Dataset** (Census Income). The goal is a binary\n",
        "classification problem: predicting whether someone has a high or low\n",
        "income based on demographics.\n",
        "\n",
        "He chooses this dataset because it represents typical enterprise tabular\n",
        "data: it has 30,000 rows, a mix of numerical and categorical features,\n",
        "and contains collinearity and interaction effects. This makes it a\n",
        "realistic test bed for the models he will demonstrate.\n",
        "\n",
        "### 18. Baseline Models\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_18.png\"\n",
        "alt=\"Slide 18\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 18</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:13:53](https://youtu.be/lx4SJOVtxI8&t=833s))\n",
        "\n",
        "The speaker outlines the three baseline models he built to bracket the\n",
        "performance possibilities: 1. **Logistic Regression:** The standard\n",
        "statistical approach. 2. **AutoML (H2O):** A stacked ensemble of many\n",
        "models (Neural Networks, GBMs, etc.) representing the “maximum” possible\n",
        "performance. 3. **OneR:** A very simple rule-based algorithm.\n",
        "\n",
        "These baselines provide the context for evaluating the interpretable\n",
        "models later.\n",
        "\n",
        "### 19. Baseline Models Plot\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_19.png\"\n",
        "alt=\"Slide 19\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 19</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:14:12](https://youtu.be/lx4SJOVtxI8&t=852s))\n",
        "\n",
        "This plot visualizes **Complexity vs. AUC** (Area Under the Curve). \\*\n",
        "**OneR** is at the bottom (AUC ~0.60) with very low complexity. \\*\n",
        "**Logistic Regression** is in the middle (AUC ~0.91). \\* **Stacked\n",
        "Ensemble** is at the top (AUC ~0.93) but with massive complexity.\n",
        "\n",
        "Shah notes that while the Stacked Ensemble wins on accuracy, the\n",
        "Logistic Regression is surprisingly close, highlighting that simpler\n",
        "models can often be “good enough.”\n",
        "\n",
        "### 20. OneR Example\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_20.png\"\n",
        "alt=\"Slide 20\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 20</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:15:17](https://youtu.be/lx4SJOVtxI8&t=917s))\n",
        "\n",
        "Shah explains the **OneR** (One Rule) algorithm. This method finds the\n",
        "single feature in the dataset that best predicts the target. In the\n",
        "example shown (Iris dataset), utilizing just “Petal Width” classifies\n",
        "96% of instances correctly.\n",
        "\n",
        "He suggests OneR is a great way to detect **Target Leakage**—if one\n",
        "feature predicts the target perfectly, it might be “cheating.” It also\n",
        "sets the floor for performance; if a complex model can’t beat OneR,\n",
        "something is wrong.\n",
        "\n",
        "### 21. Baseline Models Plot (Recap)\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_21.png\"\n",
        "alt=\"Slide 21\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 21</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:16:36](https://youtu.be/lx4SJOVtxI8&t=996s))\n",
        "\n",
        "Returning to the complexity plot, Shah reiterates the performance gap.\n",
        "The AutoML model sets the “ceiling” at 0.93 AUC.\n",
        "\n",
        "The goal for the rest of the presentation is to see where the\n",
        "interpretable models (Rulefit, GA2M, etc.) fall on this graph. Can they\n",
        "approach the 0.93 AUC of the ensemble without incurring the massive\n",
        "complexity penalty?\n",
        "\n",
        "### 22. Section 3: Rulefit\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_22.png\"\n",
        "alt=\"Slide 22\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 22</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:18:18](https://youtu.be/lx4SJOVtxI8&t=1098s))\n",
        "\n",
        "This slide introduces the first major interpretable technique:\n",
        "**Rulefit**. Shah mentions familiarity with this from his time at Data\n",
        "Robot and notes that it is a powerful way to combine the benefits of\n",
        "trees and linear models.\n",
        "\n",
        "### 23. What is Rulefit?\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_23.png\"\n",
        "alt=\"Slide 23\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 23</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:18:30](https://youtu.be/lx4SJOVtxI8&t=1110s))\n",
        "\n",
        "**Rulefit** is an algorithm developed by Friedman and Popescu (2008). It\n",
        "works by: 1. Building a random forest of short, “stumpy” decision trees.\n",
        "2. Extracting each path through the trees as a “Rule.” 3. Using these\n",
        "rules as binary features in a sparse linear model (Lasso).\n",
        "\n",
        "This approach allows the model to capture interactions (via the trees)\n",
        "while maintaining the interpretability of a linear equation.\n",
        "\n",
        "### 24. H2O Rulefit Output\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_24.png\"\n",
        "alt=\"Slide 24\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 24</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:22:19](https://youtu.be/lx4SJOVtxI8&t=1339s))\n",
        "\n",
        "Shah displays the output from the **H2O Rulefit** implementation. The\n",
        "model generates human-readable rules, such as: *“If Education \\< 12 AND\n",
        "Capital Gain \\< \\$7000, THEN Coefficient is negative.”*\n",
        "\n",
        "He notes that while the rules are readable, the raw output can look like\n",
        "“computer-ese.” However, it allows a data scientist to identify specific\n",
        "segments of the population (e.g., low education, low capital gain) that\n",
        "strongly drive the prediction.\n",
        "\n",
        "### 25. Overlapping Rules\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_25.png\"\n",
        "alt=\"Slide 25\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 25</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:24:30](https://youtu.be/lx4SJOVtxI8&t=1470s))\n",
        "\n",
        "A key characteristic of Rulefit is that the rules **overlap**. A single\n",
        "data point might satisfy multiple rules simultaneously.\n",
        "\n",
        "Shah points out that this adds a layer of complexity to\n",
        "interpretability. To understand a prediction, you have to sum up the\n",
        "coefficients of *all* the rules that apply to that person. This is\n",
        "different from a decision tree where you fall into exactly one leaf\n",
        "node.\n",
        "\n",
        "### 26. H2O Rulefit with Linear Terms\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_26.png\"\n",
        "alt=\"Slide 26\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 26</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:25:55](https://youtu.be/lx4SJOVtxI8&t=1555s))\n",
        "\n",
        "One limitation of pure rules is handling continuous variables (like age\n",
        "or miles driven). Rules have to “bin” these variables (e.g., Age \\< 30,\n",
        "Age 30-40).\n",
        "\n",
        "Shah explains that H2O Rulefit solves this by including **Linear\n",
        "Terms**. The model can use rules for non-linear interactions *and*\n",
        "standard linear coefficients for continuous trends. This hybrid approach\n",
        "boosts the AUC significantly (up to 0.88 in this example) by capturing\n",
        "linear relationships more naturally.\n",
        "\n",
        "### 27. Rulefit Results\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_27.png\"\n",
        "alt=\"Slide 27\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 27</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:27:04](https://youtu.be/lx4SJOVtxI8&t=1624s))\n",
        "\n",
        "This slide plots the performance of Rulefit models with varying numbers\n",
        "of rules. Shah demonstrates that by increasing the number of rules\n",
        "(complexity), the AUC climbs closer to the Stacked Ensemble.\n",
        "\n",
        "He concludes that Rulefit is a versatile tool. You can tune the “dial”\n",
        "of complexity: fewer rules for more interpretability, or more rules for\n",
        "higher accuracy, often getting very competitive performance.\n",
        "\n",
        "### 28. Section 4: GA2M\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_28.png\"\n",
        "alt=\"Slide 28\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 28</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:31:35](https://youtu.be/lx4SJOVtxI8&t=1895s))\n",
        "\n",
        "The presentation moves to the second technique: **GA2M** (Generalized\n",
        "Additive Models with pairwise interactions). Shah notes that while GAMs\n",
        "have existed for a while, modern implementations like Microsoft’s\n",
        "**Explainable Boosting Machines (EBM)** have made them much more\n",
        "accessible and powerful.\n",
        "\n",
        "### 29. What is GA2M?\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_29.png\"\n",
        "alt=\"Slide 29\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 29</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:32:02](https://youtu.be/lx4SJOVtxI8&t=1922s))\n",
        "\n",
        "**GA2M** is essentially a linear model where features are binned, and\n",
        "pairwise interactions are automatically detected. Shah highlights\n",
        "**InterpretML**, an open-source library from Microsoft that implements\n",
        "this via EBMs.\n",
        "\n",
        "The model structure is additive:\n",
        "$g(E[y]) = \\beta_0 + \\sum f_j(x_j) + \\sum f_{ij}(x_i, x_j)$. This means\n",
        "the final score is just the sum of individual feature scores and\n",
        "interaction scores, making it very transparent.\n",
        "\n",
        "### 30. GA2M Binning\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_30.png\"\n",
        "alt=\"Slide 30\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 30</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:32:42](https://youtu.be/lx4SJOVtxI8&t=1962s))\n",
        "\n",
        "Shah explains how GA2M handles numerical data. Instead of a single slope\n",
        "coefficient (like in logistic regression), the model **bins** the\n",
        "continuous feature (e.g., dividing “criminal history” into ranges).\n",
        "\n",
        "Each bin gets its own coefficient. This allows the model to learn\n",
        "non-linear patterns (e.g., risk might go up, then down, then up again as\n",
        "a variable increases) while remaining easy to inspect.\n",
        "\n",
        "### 31. Interactions in GA2M\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_31.png\"\n",
        "alt=\"Slide 31\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 31</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:33:08](https://youtu.be/lx4SJOVtxI8&t=1988s))\n",
        "\n",
        "The “2” in GA2M stands for **pairwise interactions**. Shah emphasizes\n",
        "that this is the model’s superpower. While standard linear models\n",
        "struggle with interactions (e.g., the combined effect of age and\n",
        "education), GA2M has an efficient algorithm to automatically find the\n",
        "most important pairs.\n",
        "\n",
        "This allows the model to achieve accuracy levels comparable to complex\n",
        "ensembles (AUC 0.93) because it captures the interaction signal that\n",
        "simple linear models miss.\n",
        "\n",
        "### 32. GA2M Visualization\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_32.png\"\n",
        "alt=\"Slide 32\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 32</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:35:14](https://youtu.be/lx4SJOVtxI8&t=2114s))\n",
        "\n",
        "Shah showcases the **InterpretML** dashboard. It provides clear\n",
        "visualizations of how each feature contributes to the prediction.\n",
        "\n",
        "In the example, we see the coefficients for different marital statuses.\n",
        "This acts like a “lookup table” for risk. Shah argues that this is very\n",
        "“model risk management friendly” because stakeholders can validate every\n",
        "single coefficient and interaction term to ensure they make business\n",
        "sense.\n",
        "\n",
        "### 33. Section 5: Rule Lists\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_33.png\"\n",
        "alt=\"Slide 33\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 33</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:40:28](https://youtu.be/lx4SJOVtxI8&t=2428s))\n",
        "\n",
        "The third approach is **Rule Lists**. Shah introduces this as a method\n",
        "to solve the “overlapping rules” problem found in Rulefit.\n",
        "\n",
        "### 34. What are Rule Lists?\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_34.png\"\n",
        "alt=\"Slide 34\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 34</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:40:48](https://youtu.be/lx4SJOVtxI8&t=2448s))\n",
        "\n",
        "**Rule Lists** are ordered sets of **IF-THEN-ELSE** statements. Unlike\n",
        "Rulefit, where you sum up multiple rules, here an observation triggers\n",
        "only the **first** rule it matches.\n",
        "\n",
        "Shah mentions implementations like **CORELS** and **SBRL** (Scalable\n",
        "Bayesian Rule Lists). The goal is to produce a concise list that a human\n",
        "can read from top to bottom to make a decision.\n",
        "\n",
        "### 35. SBRL Process\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_35.png\"\n",
        "alt=\"Slide 35\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 35</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:41:09](https://youtu.be/lx4SJOVtxI8&t=2469s))\n",
        "\n",
        "Creating an optimal rule list is computationally expensive because the\n",
        "algorithm must search through many permutations to find the best order.\n",
        "\n",
        "Shah explains the logic: The algorithm finds a rule that covers a subset\n",
        "of data, removes those instances, and then finds the next rule for the\n",
        "remaining data. This sequential “peeling off” of data creates the\n",
        "IF-ELSE structure.\n",
        "\n",
        "### 36. SBRL Output Example\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_36.png\"\n",
        "alt=\"Slide 36\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 36</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:41:45](https://youtu.be/lx4SJOVtxI8&t=2505s))\n",
        "\n",
        "The output of an SBRL model is shown. It reads like a checklist: 1. *IF\n",
        "Capital Gain \\> \\$7500 -\\> High Income (99% prob)* 2. *ELSE IF Education\n",
        "\\< 4 -\\> Low Income (90% prob)* 3. *ELSE…*\n",
        "\n",
        "Shah highlights the simplicity: *“You just go down the list until you\n",
        "find the rule… much easier to explain to those marketing people.”* The\n",
        "trade-off is a drop in accuracy (AUC 0.86) compared to GA2M or Rulefit.\n",
        "\n",
        "### 37. Section 6: Scorecard\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_37.png\"\n",
        "alt=\"Slide 37\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 37</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:44:52](https://youtu.be/lx4SJOVtxI8&t=2692s))\n",
        "\n",
        "The final approach is the **Scorecard**. Shah introduces this as perhaps\n",
        "the simplest and most widely recognized format for decision-making in\n",
        "industries like credit and criminal justice.\n",
        "\n",
        "### 38. What are Scorecards?\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_38.png\"\n",
        "alt=\"Slide 38\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 38</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:45:04](https://youtu.be/lx4SJOVtxI8&t=2704s))\n",
        "\n",
        "**Scorecards** are simple additive models where features are assigned\n",
        "integer “points.” To get a prediction, you simply add up the points.\n",
        "\n",
        "Shah mentions tools like **Optbinning** and **SLIM** (Sparse Linear\n",
        "Integer Models). This format is beloved in operations because it can be\n",
        "printed on a physical card or implemented in a basic spreadsheet.\n",
        "\n",
        "### 39. Scorecard Example\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_39.png\"\n",
        "alt=\"Slide 39\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 39</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:46:08](https://youtu.be/lx4SJOVtxI8&t=2768s))\n",
        "\n",
        "This slide shows a scorecard built for the Adult dataset. \\* *Capital\n",
        "Gain \\> 7000? +29 points.* \\* *Age \\< 25? -5 points.*\n",
        "\n",
        "Shah expresses a personal preference for this over raw coefficients: *“I\n",
        "actually like this better… I think it’s a little easier to understand\n",
        "which features are most important.”* The integer points make the\n",
        "“weight” of each factor immediately obvious to a layperson.\n",
        "\n",
        "### 40. Summary\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_40.png\"\n",
        "alt=\"Slide 40\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 40</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:51:11](https://youtu.be/lx4SJOVtxI8&t=3071s))\n",
        "\n",
        "Shah begins to wrap up the presentation, preparing to consolidate the\n",
        "four methods (Rulefit, GA2M, Rule Lists, Scorecards) into a final\n",
        "comparison.\n",
        "\n",
        "### 41. Complexity vs AUC Summary Plot\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_41.png\"\n",
        "alt=\"Slide 41\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 41</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:51:13](https://youtu.be/lx4SJOVtxI8&t=3073s))\n",
        "\n",
        "This is the definitive comparison graph of the talk. It places all\n",
        "discussed models on the **Complexity vs. AUC** plane. \\* **GA2M (EBM)**\n",
        "and **Rulefit** sit high up, offering near-SOTA accuracy with moderate\n",
        "interpretability. \\* **Scorecards** and **Rule Lists** sit lower on\n",
        "accuracy but offer maximum simplicity.\n",
        "\n",
        "Shah summarizes the trade-off: *“The Rule Lists and Scorecard… you lose\n",
        "a little bit \\[of accuracy\\]… but we talked about the trade-offs of\n",
        "being able to easily understand.”*\n",
        "\n",
        "### 42. Take Away\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_42.png\"\n",
        "alt=\"Slide 42\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 42</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:52:08](https://youtu.be/lx4SJOVtxI8&t=3128s))\n",
        "\n",
        "The final message is a call to action: **Try these approaches.**\n",
        "\n",
        "Shah encourages data scientists to add these tools to their toolkit. He\n",
        "asks them to consider the specific needs of their problem: Is it about\n",
        "transparency in *calculation* (Scorecard)? Or understanding *factors*\n",
        "(GA2M)? Often, a simple model that gets deployed is far better than a\n",
        "complex model that gets stuck in review.\n",
        "\n",
        "### 43. Conclusion\n",
        "\n",
        "<figure>\n",
        "<img\n",
        "src=\"https://rajivshah.com/blog/images/interpretable-ml-models/slide_43.png\"\n",
        "alt=\"Slide 43\" />\n",
        "<figcaption aria-hidden=\"true\">Slide 43</figcaption>\n",
        "</figure>\n",
        "\n",
        "([Timestamp: 00:52:52](https://youtu.be/lx4SJOVtxI8&t=3172s))\n",
        "\n",
        "The presentation concludes with Rajiv Shah’s contact information. He\n",
        "mentions an upcoming blog post that will synthesize these topics and\n",
        "invites the audience to reach out with questions or feedback.\n",
        "\n",
        "He reiterates that these interpretable models are often easier to get\n",
        "“buy-in” for, making them a pragmatic choice for real-world data science\n",
        "success.\n",
        "\n",
        "------------------------------------------------------------------------\n",
        "\n",
        "*This annotated presentation was generated from the talk using\n",
        "AI-assisted tools. Each slide includes timestamps and detailed\n",
        "explanations.*"
      ],
      "id": "f491e442-48ec-4029-a8dc-d239d494ce4d"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  }
}