{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Using xgbfi for revealing feature interactions\n",
        "\n",
        "### Introduction\n",
        "\n",
        "Tree based methods excel in using feature or variable interactions. As a\n",
        "tree is built, it picks up on the [interaction of\n",
        "features](https://datamining.bus.utk.edu/Documents/Decision-Trees-for-Predictive-Modeling-(Neville).pdf).\n",
        "For example, buying ice cream may not be affected by having extra money\n",
        "unless the weather is hot. It is the interaction of both of these\n",
        "features that can affect whether ice cream will be consumed.\n",
        "\n",
        "The traditional manner for examining interactions is relying on measures\n",
        "of [variable\n",
        "importance](https://www.quora.com/How-do-I-find-variable-importance-in-random-forest/answer/Rajiv-Shah-6).\n",
        "However, these measures donâ€™t provide insights into second or third\n",
        "order interactions. Identifying these interactions are important in\n",
        "building better models, especially when finding features to use within\n",
        "linear models.\n",
        "\n",
        "In this post, I show how to find higher order interactions using\n",
        "[XGBoost Feature Interactions &\n",
        "Importance](https://github.com/Far0n/xgbfi). This tool has been\n",
        "available for a while, but outside of\n",
        "[kagglers](https://www.kaggle.com/c/bnp-paribas-cardif-claims-management/forums/t/18754/feature-engineering/107518),\n",
        "it has received relatively little attention.\n",
        "\n",
        "As a starting point, I used the Ice Cream dataset to illustrate using\n",
        "xgbfi. This walkthrough is in R, but python instructions are also\n",
        "available at the repo. I am going to break the code into three sections,\n",
        "the initial build of the model, exporting the files necessary for xgbfi,\n",
        "and running xgbi.\n",
        "\n",
        "#### Building the model\n",
        "\n",
        "Lets start by loading the data:\n",
        "\n",
        "    library(xgboost)\n",
        "    library(Ecdat)\n",
        "    data(Icecream)\n",
        "    train.data <- data.matrix(Icecream[,-1])\n",
        "\n",
        "The next step is running xgboost:\n",
        "\n",
        "    bst <- xgboost(data = train.data, label = Icecream$cons, max.depth = 3, eta = 1, nthread = 2, nround = 2, objective = \"reg:linear\")\n",
        "\n",
        "To better understand how the model is working, lets go ahead and look at\n",
        "the trees:\n",
        "\n",
        "    xgb.plot.tree(feature_names = names((Icecream[,-1])), model = bst)\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://rajivshah.com/blog/images/xgplot.png\"\n",
        "alt=\"xg tree plot\" />\n",
        "<figcaption aria-hidden=\"true\">xg tree plot</figcaption>\n",
        "</figure>\n",
        "\n",
        "The results here line up with our intution. Hot days seems to be the\n",
        "biggest variable by just eyeing the plot. This lines up with the results\n",
        "of a variable importance calculation:\n",
        "\n",
        "    > xgb.importance(colnames(train.data, do.NULL = TRUE, prefix = \"col\"), model = bst)\n",
        "       Feature       Gain      Cover Frequency\n",
        "    1:    temp 0.75047187 0.66896552 0.4444444\n",
        "    2:  income 0.18846270 0.27586207 0.4444444\n",
        "    3:   price 0.06106542 0.05517241 0.1111111\n",
        "\n",
        "All of this should be very familiar to anyone who has used decision\n",
        "trees for modeling. **But what are the second order interactions? Third\n",
        "order interactions? Can you rank them?**\n",
        "\n",
        "#### Exporting the tree\n",
        "\n",
        "The next step involves saving the tree and moving it outside of R so\n",
        "xgbfi can parse the tree. The code below will help to create two files\n",
        "that are needed:`xgb.dump` and `fmap.text`.\n",
        "\n",
        "    featureList <- names(Icecream[,-1])\n",
        "    featureVector <- c() \n",
        "    for (i in 1:length(featureList)) { \n",
        "      featureVector[i] <- paste(i-1, featureList[i], \"q\", sep=\"\\t\") \n",
        "    }\n",
        "    write.table(featureVector, \"fmap.txt\", row.names=FALSE, quote = FALSE, col.names = FALSE)\n",
        "    xgb.dump(model = bst, fname = 'xgb.dump', fmap = \"fmap.txt\", with.stats = TRUE)\n",
        "\n",
        "#### Running xgbfi\n",
        "\n",
        "The first step is to clone the [xgbfi\n",
        "repository](https://github.com/Far0n/xgbfi) onto your computer. Then\n",
        "copy the files `xgb.dump` and `fmap.text` to the bin directory.\n",
        "\n",
        "Go to your terminal or command line and run:\n",
        "`XgbFeatureInteractions.exe` application. On a mac, [download\n",
        "mono](http://www.mono-project.com/download/) and then run the command:\n",
        "`mono XgbFeatureInteractions.exe`. There is also a\n",
        "`XgbFeatureInteractions.exe.config` file that contains configuration\n",
        "settings in the bin directory.\n",
        "\n",
        "After the application runs, it will write out an excel spreadsheet\n",
        "titled: `XgbFeatureInteractions.xlsx`. This spreadsheet has the good\n",
        "stuff! Open up the spreadsheet and you should see:\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://rajivshah.com/blog/images/firstinteraction.png\"\n",
        "alt=\"interaction depth 0\" />\n",
        "<figcaption aria-hidden=\"true\">interaction depth 0</figcaption>\n",
        "</figure>\n",
        "\n",
        "This tab of the spreadsheet shows the first order interactions. These\n",
        "results are similar to what variable importance showed. The good stuff\n",
        "is when you click on the tab for Interaction Depth 1 or Interaction\n",
        "Depth 2.\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://rajivshah.com/blog/images/secondinteraction.png\"\n",
        "alt=\"interaction depth 1\" />\n",
        "<figcaption aria-hidden=\"true\">interaction depth 1</figcaption>\n",
        "</figure>\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://rajivshah.com/blog/images/thirdinteraction.png\"\n",
        "alt=\"interaction depth 2\" />\n",
        "<figcaption aria-hidden=\"true\">interaction depth 2</figcaption>\n",
        "</figure>\n",
        "\n",
        "It is now possible to rank the higher order interactions. With the\n",
        "simple dataset, you can see that the results out of xgbfi match what is\n",
        "happening in the tree. The real value of this tool is for much larger\n",
        "datasets, where its difficult to examine the trees for the interactions."
      ],
      "id": "87bce70c-8853-426e-a161-266a12133666"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  }
}