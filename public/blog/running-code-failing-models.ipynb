{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Running Code and Failing Models\n",
        "\n",
        "![img](https://cdn-images-1.medium.com/max/1600/1*jL9fT-oAR6Ki3HOvXpwMLQ.png)\n",
        "Source: Yuriy Guts selection from Shutterstock\n",
        "\n",
        "Machine learning is a glass cannon. When used correctly, it can be a\n",
        "truly transformative technology, but just a small oversight can cause it\n",
        "to become misleading and even actively harmful. Even if all the code\n",
        "runs and the model seems to be spitting out reasonable answers, it’s\n",
        "possible for a model to encode fundamental data science mistakes that\n",
        "invalidate its results. These errors might seem small, but the effects\n",
        "can be disastrous when the model is used to make decisions in the real\n",
        "world.\n",
        "\n",
        "The promise and power of AI lead many researchers to gloss over the ways\n",
        "in which things can go wrong when building and operationalizing machine\n",
        "learning models. As a data scientist, one of my passions is to reproduce\n",
        "research papers as a learning exercise. Along the way, I have uncovered\n",
        "cases where the research was published with faulty methodologies. My\n",
        "hope is that this analysis can increase awareness about data science\n",
        "mistakes and raise the standards for machine learning in research. For\n",
        "example, last year I shared an analysis of a project by Harvard and\n",
        "Google researchers that contained fundamental errors. The researchers\n",
        "refused to fix their mistake even when confronted with it directly.\n",
        "\n",
        "Over the holidays, I used DataRobot to reproduce a few machine learning\n",
        "benchmarks. I found many examples of machine learning code that ran\n",
        "without errors but that were built using flawed data science practices.\n",
        "The examples I share in this post come from the world’s best data\n",
        "scientists and affect hundreds of peer-reviewed research publications.\n",
        "As these examples show, errors in machine learning can be subtle. The\n",
        "key to finding these errors is to work with a tool that offers\n",
        "guardrails and insights along the way.\n",
        "\n",
        "## Target Leakage in a fast.ai Example\n",
        "\n",
        "*Deep Learning for Coders with fastai and PyTorch: AI Applications\n",
        "Without a PhD* by Jeremy Howard and Sylvain Gugger is a hands-on guide\n",
        "that helps people with little math background understand and use deep\n",
        "learning quickly. In the section about tabular datasets, the authors use\n",
        "the Blue Book for Bulldozers problem, the goal of which is to predict\n",
        "the sale price for heavy equipment at auction. I tried to replicate\n",
        "their machine learning model and wasn’t able to beat their model’s\n",
        "predictive performance, which piqued my interest.\n",
        "\n",
        "After carefully inspecting their code, I found a mistake in their\n",
        "validation dataset. Their code attempted to create a validation test set\n",
        "based on a prediction point of November 1, 2011. The goal was to split\n",
        "the data at this point so that you could train on the data known at\n",
        "prediction time. The performance of the model is then analyzed on a test\n",
        "set, which is located after the prediction point. Unfortunately, the\n",
        "code was not written correctly; there was contamination from the future\n",
        "in the training data.\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://rajivshah.com/blog/images/leakage1.png\"\n",
        "alt=\"Leakage.png\" />\n",
        "<figcaption aria-hidden=\"true\">Leakage.png</figcaption>\n",
        "</figure>\n",
        "\n",
        "The code below might at first look like it separates data before and\n",
        "after November 1, 2011, but there’s a subtle mistake that includes\n",
        "future dates. The use of information in the model training process that\n",
        "would not be expected at prediction time is known as **target leakage**,\n",
        "and it led to an over-optimistic accuracy. Because I used DataRobot,\n",
        "which requires and validates a date when creating a validation dataset\n",
        "based on time, I was able to find the mistake in the fast.ai book.\n",
        "\n",
        "After the target leakage was fixed, the fast.ai scores dropped, and I\n",
        "was able to reproduce the results outside of fast.ai. This simple coding\n",
        "mistake led to a notebook and model that appeared valid. If this model\n",
        "were put into production, the results would have been much worse on new\n",
        "data. After I identified this issue, Jeremy Howard agreed to add a note\n",
        "in the course materials.\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://rajivshah.com/blog/images/fastai2.png\"\n",
        "alt=\"fastai2.png\" />\n",
        "<figcaption aria-hidden=\"true\">fastai2.png</figcaption>\n",
        "</figure>\n",
        "\n",
        "## SARCOS Dataset Failure\n",
        "\n",
        "The SARCOS dataset is a widely used benchmark dataset in machine\n",
        "learning. Based on predicting the movement of a robotic arm, SARCOS\n",
        "appears in more than one hundred academic papers. I tested this dataset\n",
        "because it appears in various benchmarks by Google and fast.ai.\n",
        "\n",
        "The SARCOS dataset is broken into two parts: a training dataset\n",
        "(sarcos_inv) and a test dataset (sarcos_inv_test). Following common data\n",
        "science practices, DataRobot broke the SARCOS training set into a\n",
        "training partition and a validation partition. I treated the SARCOS test\n",
        "set (sarcos_inv_test) as a holdout. When I looked at the results, I\n",
        "immediately noticed something suspicious. Do you see it?\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://rajivshah.com/blog/images/sarcos3.png\"\n",
        "alt=\"sarcos3.png\" />\n",
        "<figcaption aria-hidden=\"true\">sarcos3.png</figcaption>\n",
        "</figure>\n",
        "\n",
        "The large drop between the validation score and the holdout score\n",
        "indicates that something is very different between the validation and\n",
        "holdout datasets. When I examined the holdout dataset (the SARCOS test\n",
        "set), I found that every row in the test set was in the training data\n",
        "too. After some investigation, I discovered that the holdout dataset was\n",
        "built out of the training dataset. Of the 4,449 examples in the test\n",
        "set, 4,445 examples are present in the training set, too. The target\n",
        "leakage here is significant. By overfitting or memorizing the training\n",
        "dataset, it’s possible to get perfect results on the test set.\n",
        "Overfitting, a well-known issue in machine learning, is illustrated in\n",
        "the following figure. The test dataset should have used out-of-sample\n",
        "testing to prevent overfitting.\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://rajivshah.com/blog/images/overfit4.png\"\n",
        "alt=\"overfit4.png\" />\n",
        "<figcaption aria-hidden=\"true\">overfit4.png</figcaption>\n",
        "</figure>\n",
        "\n",
        "Target leakage helped to explain the very low scores of the deep\n",
        "learning models. For comparison, a random forest model achieves 2.38\n",
        "mean squared error (MSE), while a deep learning model overfits and\n",
        "produces 0.038 MSE. Judging from the suspiciously large difference\n",
        "between the models, it appears that the deep learning model just\n",
        "memorized the training data, which is why it had such low error.\n",
        "\n",
        "The consequences of this target leakage are far-reaching. More than one\n",
        "hundred journal articles relied on this dataset. Thousands of data\n",
        "scientists have used it to benchmark their machine learning code.\n",
        "Researcher Kai Arulkumaran has already acknowledged this issue and now\n",
        "the research community is dealing with the ramifications of the target\n",
        "leakage.\n",
        "\n",
        "Why wasn’t this error discovered earlier? When I reproduced the SARCOS\n",
        "benchmarks, I used a tool that includes technical safeguards for proper\n",
        "validation splits and provides transparency in the display of the\n",
        "results of each split. DataRobot’s AutoML was designed by data\n",
        "scientists to prevent these sorts of issues. In contrast, working within\n",
        "code, it was quite easy to overlook this fundamental issue. After all,\n",
        "thousands of data scientists have rerun their code and published their\n",
        "results without a second thought.\n",
        "\n",
        "## Poker Hand Dataset\n",
        "\n",
        "The Poker Hand dataset is another widely used benchmark dataset in\n",
        "machine learning. It’s used to predict poker hands (for example, a full\n",
        "house from five cards). The fast.ai and Google benchmarks for this model\n",
        "use the accuracy metric. Accuracy is a measurement for assessing the\n",
        "predictive performance of a model (basically, the percentage of\n",
        "predictions that are correct). Although it’s easy to get running code\n",
        "with the accuracy metric, it’s not good data science practice for this\n",
        "problem.\n",
        "\n",
        "When DataRobot builds a model with the Poker Hand dataset, by default,\n",
        "it uses log loss as an optimization metric. Log loss is a measure of\n",
        "error for a model. At DataRobot, we believe that it isn’t good practice\n",
        "to use accuracy as your metric on a classification project with\n",
        "imbalanced classes. With imbalanced data, you can easily build a highly\n",
        "accurate model that’s useless.\n",
        "\n",
        "To understand why accuracy isn’t the best metric when classifying\n",
        "unbalanced data, consider the following figure. Minesweeper is a popular\n",
        "game where the goal is to identify a few mines that are scattered across\n",
        "a board. Because there are a lot of squares with no mines, you could\n",
        "generate a very accurate model just by predicting that every square is\n",
        "safe. Although a 99% accurate model for Minesweeper sounds impressive,\n",
        "it’s not very useful.\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://rajivshah.com/blog/images/minesweeper5.png\"\n",
        "alt=\"minesweeper5.png\" />\n",
        "<figcaption aria-hidden=\"true\">minesweeper5.png</figcaption>\n",
        "</figure>\n",
        "\n",
        "Automated feature selection in DataRobot provides a more parsimonious\n",
        "featurelist. In the Poker Hand dataset, DataRobot created a DR Reduced\n",
        "Features list with only six features. The starting feature list for this\n",
        "dataset, Cat+Cont, contained 15 features. The leaderboard below shows\n",
        "that the simpler DR Reduced Features list performs better than the full\n",
        "Cat+Cont feature list. The model below was optimized on log loss, but I\n",
        "am viewing the accuracy metrics for comparison to the existing\n",
        "benchmarks.\n",
        "\n",
        "<figure>\n",
        "<img src=\"https://rajivshah.com/blog/images/DRreduce6.png\"\n",
        "alt=\"DRreduce6.png\" />\n",
        "<figcaption aria-hidden=\"true\">DRreduce6.png</figcaption>\n",
        "</figure>\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "I have shared simple examples of how data scientists can have running\n",
        "code, but failed models. After spending a week going through a half\n",
        "dozen datasets, I am even more convinced that automation with technical\n",
        "safeguards is a required part of building trusted AI. The mistakes I’ve\n",
        "shared here are not isolated incidents.\n",
        "\n",
        "The issues go beyond the reproducibility crisis for machine learning\n",
        "research. It’s a great first step for researchers to publish their code\n",
        "and make the data available, but as these examples show, sharing code\n",
        "isn’t enough to validate models. So, what should you do about this?\n",
        "\n",
        "In regulated industries, there are processes in place to validate\n",
        "running code (for example, building a challenger model using a different\n",
        "technical framework). For its safeguards and transparency, many\n",
        "organizations use DataRobot to validate models. Just rereading or\n",
        "rerunning a project isn’t enough to identify errors.\n",
        "\n",
        "## Links\n",
        "\n",
        "-   [Stand Up for Best Practices (Harvard\n",
        "    Leakage)](https://medium.com/data-science/stand-up-for-best-practices-8a8433d3e0e8)\n",
        "-   [Fast.AI Issue](https://github.com/fastai/fastbook/issues/325)\n",
        "-   [SARCOS](https://github.com/Kaixhin/SARCOS)"
      ],
      "id": "722e69c4-1683-4e62-96ca-57ea70398d44"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  }
}